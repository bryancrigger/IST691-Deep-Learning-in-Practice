{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42bwvaz-A9AA"
      },
      "source": [
        "# IST 691 Deep Learning in Practice\n",
        "\n",
        "**Homework 2**\n",
        "\n",
        "Name:\n",
        "\n",
        "SUID:\n",
        "\n",
        "*Save this notebook into your Google Drive. The notebook has appropriate comments at the top of code cells to indicate whether you need to modify them or not. Answer your questions directly in the notebook. Remember to use the GPU as your runtime. Once finished, run ensure all code blocks are run, download the notebook and submit through Blackboard.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpmhSKf6UKmj"
      },
      "source": [
        "### Q1\n",
        "\n",
        "Explain the differences between convolutional neural networks and a multi-layer perceptron. Explain whether the following statement is true, and if true, when it could be true.\n",
        "\n",
        "'An MLP can represent the same functions as a CNN.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIpQY40pUlVy"
      },
      "source": [
        "*answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ0fDXyhUoCx"
      },
      "source": [
        "### Q2\n",
        "\n",
        "In class, we saw an example of autoencoders being able to remove the noise of an image. Explain why this happens and what the limits of such funcionality are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URzCo1Bjn66i"
      },
      "source": [
        "*answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV6HB8ARWGEB"
      },
      "source": [
        "### Q3\n",
        "\n",
        "When using transfer learning models, sometimes we get better results by fine-tuning, and some other times we get better results by freezing the parameters before training. Under what circumstances should we fine-tune the model in order to get a better result? And, under what circumstances should we freeze the parameters instead?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHYoOL_Fn9D6"
      },
      "source": [
        "*answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMnHyNXTn_PC"
      },
      "source": [
        "### Q4: MLP vs CNN\n",
        "\n",
        "Below, there are two neural networks for classifying MNIST digits: `model_mlp`  is an MLP with no hidden layers (the smallest possible) and 7,850 parameters. Evaluate the performance of this model below.\n",
        "\n",
        "Then, define a convolutional neural network with similar a number of parameters and evaluate its performance. Can it do better? Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Ym1hjSn-c2"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model_mlp = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape = input_shape),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(num_classes, activation = 'softmax'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_mlp.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3__Yo5Y6xOvz"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY CELL\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "model_mlp.compile(loss = 'categorical_crossentropy',\n",
        "                  optimizer = 'adam',\n",
        "                  metrics = ['accuracy'])\n",
        "\n",
        "model_mlp.fit(x_train,\n",
        "              y_train,\n",
        "              batch_size = batch_size,\n",
        "              epochs = epochs,\n",
        "              validation_split = 0.1,\n",
        "              verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AleryIHdxVTE"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY CELL\n",
        "score = model_mlp.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU7Y2sRVxXJZ"
      },
      "outputs": [],
      "source": [
        "# DEFINE YOUR OWN CNN SO THAT THE PARAMETERS ARE FEWER THAN THE MLP\n",
        "model_cnn = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        ....\n",
        "        layers.Dense(num_classes, activation = 'softmax'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg_0a0DVyYSR"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY CELL\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "model_cnn.compile(loss = 'categorical_crossentropy',\n",
        "                  optimizer = 'adam',\n",
        "                  metrics = ['accuracy'])\n",
        "model_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tbq5a6wfy_Ix"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY CELL\n",
        "score = model_cnn.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdCoPk6A8wXJ"
      },
      "source": [
        "**Did the CNN do better than the MLP? Why or why not?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*answer here*"
      ],
      "metadata": {
        "id": "I9ENK5oR05jB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFZBXr4B1iBR"
      },
      "source": [
        "### Q5: Transfer learning\n",
        "\n",
        "We are going to classify beans using transfer learning (read more about the dataset [here](https://www.tensorflow.org/datasets/catalog/beans). In the code below, use the `ResNet50` model available in Keras to classify the beans dataset (3 classes). **Do not fine tune `ResNet50`**. What is the performance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFmR2-Uv5_Ct"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY CELL\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# loading images and labels\n",
        "(train_ds, train_labels), (test_ds, test_labels) = tfds.load(\n",
        "    'beans',\n",
        "    split = ['train[:70%]', 'train[:30%]'], # train/test split\n",
        "    batch_size = -1,\n",
        "    as_supervised = True  # include labels\n",
        ")\n",
        "\n",
        "# resizing images\n",
        "train_ds = tf.image.resize(train_ds, (200, 200))\n",
        "test_ds = tf.image.resize(test_ds, (200, 200))\n",
        "\n",
        "# transforming labels to correct format\n",
        "train_labels = to_categorical(train_labels, num_classes=3)\n",
        "test_labels = to_categorical(test_labels, num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHFh3uyU5X99"
      },
      "outputs": [],
      "source": [
        "# IMPORT THE APPROPRIATE MODEL HERE\n",
        "from tensorflow.keras.applications...  import ...\n",
        "from tensorflow.keras.applications... import preprocess_input\n",
        "\n",
        "## loading ResNet50 model\n",
        "base_model = ???\n",
        "base_model.trainable = ???\n",
        "\n",
        "## preprocessing input\n",
        "train_ds = preprocess_input(train_ds)\n",
        "test_ds = preprocess_input(test_ds)\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "prediction_layer = layers.Dense(3, activation = 'softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    flatten_layer,\n",
        "    layers.Dropout(0.2),\n",
        "    prediction_layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exmwjiyT5wa4"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY CELL\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow import keras\n",
        "\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRBrMvl65zQ3"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY CELL\n",
        "model.fit(train_ds, train_labels, epochs = 5, validation_split = 0.2, batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WFHScEp53b3"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY CELL\n",
        "score = model.evaluate(test_ds, test_labels, verbose = 0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB9ltzce7mjE"
      },
      "source": [
        "### Q6: Autoencoder\n",
        "\n",
        "Modify the convolutional autoencoder for MNIST we saw in class so that the embedding has the following structure:\n",
        "- Conv2D: 8 filters, Kernel (3, 3)\n",
        "- MaxPooling: Size (2, 2)\n",
        "- Conv2D: 3 filters, Kernel (3, 3)\n",
        "- MaxPooling: Size (2, 2)\n",
        "- Conv2D: 1 filters, Kernel (3, 3)\n",
        "\n",
        "After making this change, you need to change the input size of the decoder function so that it can accept the output of the encoder. What is the performance of your model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-kgpVhF7e_U"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import h5py\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, Dense, Input, MaxPooling2D, UpSampling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "# data now has a different shape\n",
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# load the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "image_height = X_train.shape[1]\n",
        "image_width = X_train.shape[2]\n",
        "number_of_pixels = image_height * image_width\n",
        "\n",
        "# cast the sample data to the current Keras floating-point type\n",
        "X_train = keras_backend.cast_to_floatx(X_train)\n",
        "X_test = keras_backend.cast_to_floatx(X_test)\n",
        "\n",
        "# reshape to 2D grid, one line per image\n",
        "X_train = X_train.reshape(X_train.shape[0], number_of_pixels)\n",
        "X_test = X_test.reshape(X_test.shape[0], number_of_pixels)\n",
        "\n",
        "# scale data to range [0, 1]\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "# reshape sample data to 4D tensor using channels_last convention\n",
        "X_train = X_train.reshape(X_train.shape[0], image_height, image_width, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], image_height, image_width, 1)\n",
        "\n",
        "# replace label data with one-hot encoded versions\n",
        "number_of_classes = 1 + max(np.append(y_train, y_test))\n",
        "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
        "y_test = np_utils.to_categorical(y_test, number_of_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVDXyiwM_Ry7"
      },
      "outputs": [],
      "source": [
        "# MODIFY THE ENCODER BELOW ACCORDING TO THE QUESTION REQUIREMENTS\n",
        "CAE_encoder_conv_1 = Conv2D(??, (??, ??), activation = 'relu', padding = 'same')\n",
        "CAE_encoder_pool_1 = MaxPooling2D((??,??), padding = 'same')\n",
        "CAE_encoder_conv_2 = Conv2D(??, (??, ??), activation = 'relu', padding = 'same')\n",
        "CAE_encoder_pool_2 = MaxPooling2D((??,??), padding = 'same')\n",
        "CAE_encoder_output = Conv2D(??, (??, ??), activation = 'relu', padding = 'same')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbg8fctb8GX9"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "CAE_decoder_up_1 = UpSampling2D((2,2))\n",
        "CAE_decoder_conv_1 = Conv2D(8, (3, 3), activation = 'relu', padding = 'same')\n",
        "CAE_decoder_up_2 = UpSampling2D((2,2))\n",
        "CAE_decoder_output = Conv2D(1, (3, 3), activation = 'sigmoid', padding = 'same')\n",
        "\n",
        "CAE_encoder_step_1 = CAE_encoder_conv_1(CAE_encoder_input)\n",
        "CAE_encoder_step_2 = CAE_encoder_pool_1(CAE_encoder_step_1)\n",
        "CAE_encoder_step_3 = CAE_encoder_conv_2(CAE_encoder_step_2)\n",
        "CAE_encoder_step_4 = CAE_encoder_pool_2(CAE_encoder_step_3)\n",
        "CAE_encoder_step_5 = CAE_encoder_output(CAE_encoder_step_4)\n",
        "\n",
        "CAE_decoder_step_1 = CAE_decoder_up_1(CAE_encoder_step_5)\n",
        "CAE_decoder_step_2 = CAE_decoder_conv_1(CAE_decoder_step_1)\n",
        "CAE_decoder_step_3 = CAE_decoder_up_2(CAE_decoder_step_2)\n",
        "CAE_decoder_step_4 = CAE_decoder_output(CAE_decoder_step_3)\n",
        "\n",
        "\n",
        "Conv_AE = Model(CAE_encoder_input, CAE_decoder_step_4)\n",
        "Conv_AE.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
        "\n",
        "\n",
        "Conv_AE_encoder_only_model = Model(CAE_encoder_input, CAE_encoder_step_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCmKgIpx9LV-"
      },
      "outputs": [],
      "source": [
        "# MODIFY THE INPUT FOR THE DECODER BELOW ACCORDING TO THE OUTPUT EXPECTED FROM THE ENCODER\n",
        "Conv_AE_decoder_only_input = Input(shape=(??, ??, ??))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7unPXGF_cbi"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "Conv_AE_decoder_only_step_1 = CAE_decoder_up_1(Conv_AE_decoder_only_input)\n",
        "Conv_AE_decoder_only_step_2 = CAE_decoder_conv_1(Conv_AE_decoder_only_step_1)\n",
        "Conv_AE_decoder_only_step_3 = CAE_decoder_up_2(Conv_AE_decoder_only_step_2)\n",
        "Conv_AE_decoder_only_step_4 = CAE_decoder_output(Conv_AE_decoder_only_step_3)\n",
        "\n",
        "Conv_AE_decoder_only_model = Model(Conv_AE_decoder_only_input, Conv_AE_decoder_only_step_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp60H-tq_cuG"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "# FIT AND EVALUATE PERFORMANCE\n",
        "Conv_AE.fit(X_train, X_train,\n",
        "               epochs = 50, batch_size = 128, shuffle = True,\n",
        "               verbose = 2,\n",
        "               validation_data = (X_test, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XnyzumB_fnY"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "def draw_predictions_set(predictions, filename = None):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    for i in range(5):\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(X_test[i].reshape(28, 28), vmin = 0, vmax = 1, cmap = 'gray')\n",
        "        ax = plt.gca()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        plt.subplot(2, 5, i + 6)\n",
        "        plt.imshow(predictions[i].reshape(28, 28), vmin = 0, vmax = 1, cmap = 'gray')\n",
        "        ax = plt.gca()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrxzJAIA_jHW"
      },
      "outputs": [],
      "source": [
        "# Test your new predictions\n",
        "Conv_predictions = Conv_AE.predict(X_test)\n",
        "draw_predictions_set(Conv_predictions, 'NB3-ConvAE-predictions')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}