{"cells":[{"cell_type":"markdown","metadata":{"id":"RZ7cPfCty5U3"},"source":["# IST 691: Deep Learning in Practice\n","\n","**Homework 3**\n","\n","Name: Bryan Crigger\n","\n","SUID: 255676562\n","\n","*Save this notebook into your Google Drive. The notebook has appropriate comments at the top of code cells to indicate whether you need to modify them or not. Answer your questions directly in the notebook. Remember to use the GPU as your runtime. Once finished, run ensure all code blocks are run, download the notebook and submit through Blackboard.*"]},{"cell_type":"markdown","metadata":{"id":"g8swbTwkCunA"},"source":["### Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60F0x-u40An9"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import TextVectorization\n","import string\n","import re\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import json\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# to build nearest neighbor model\n","from sklearn.neighbors import NearestNeighbors"]},{"cell_type":"markdown","metadata":{"id":"p3AEhdYAMBPN"},"source":["In this homework, we will perform **sarcasm detection** with [Onion](https://www.theonion.com/) vs [HuffPost](https://www.huffpost.com/) headlines, using LSTM. We will first load the data and generate the training and testing input and labels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlmQdvJtL_Si"},"outputs":[],"source":["! wget -nc -q https://github.com/mrech/NLP_TensorFlow/blob/master/0_Sentiment_in_Text/Sarcasm_Headlines_Dataset_v2.json?raw=true"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fzE7kwA0MdYc"},"outputs":[],"source":["# read the downloaded dataset\n","df = pd.read_json('Sarcasm_Headlines_Dataset_v2.json?raw=true', lines = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oefWYDEBBoQz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701745797504,"user_tz":360,"elapsed":8,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"fbce5bc8-a577-48be-c14e-8fe2db5abc97"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 28619 entries, 0 to 28618\n","Data columns (total 3 columns):\n"," #   Column        Non-Null Count  Dtype \n","---  ------        --------------  ----- \n"," 0   is_sarcastic  28619 non-null  int64 \n"," 1   headline      28619 non-null  object\n"," 2   article_link  28619 non-null  object\n","dtypes: int64(1), object(2)\n","memory usage: 670.9+ KB\n"]}],"source":["# get information about the data frame\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zt5i54PMfLF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701745797504,"user_tz":360,"elapsed":6,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"644e8459-83ee-4b09-c0a8-c9883477cbae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['thirtysomething scientists unveil doomsday clock of hair loss',\n","        1],\n","       ['dem rep. totally nails why congress is falling short on gender, racial equality',\n","        0],\n","       ['eat your veggies: 9 deliciously different recipes', 0],\n","       ['inclement weather prevents liar from getting to work', 1],\n","       [\"mother comes pretty close to using word 'streaming' correctly\",\n","        1]], dtype=object)"]},"metadata":{},"execution_count":5}],"source":["# take a peek at the key data\n","df[['headline', 'is_sarcastic']].head(5).values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxA-gljoMt4G"},"outputs":[],"source":["# the training input sequence will be in variable seq_padd_train and the label in train_y\n","# The testing input sequence will be in variable seq_padd_test and the label in test_y\n","headlines = df['headline'].values.tolist()\n","sarcastic = df['is_sarcastic'].values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8L2cvpK9Mt4H"},"outputs":[],"source":["training_size = 20000\n","test_size = 6709\n","\n","train_x = headlines[:training_size]\n","test_x = headlines[training_size:]\n","train_y = np.array(sarcastic[:training_size])\n","test_y = np.array(sarcastic[training_size:])\n","\n","# sequence of words input\n","max_len = 16\n","\n","tokenizer = Tokenizer(oov_token = '<OOV>')\n","tokenizer.fit_on_texts(train_x)\n","\n","word_index = tokenizer.word_index\n","index_word = {v: k for k, v in word_index.items()}\n","vocab_size = len(word_index)\n","sequence_train = tokenizer.texts_to_sequences(train_x)\n","seq_padd_train = pad_sequences(sequence_train,\n","                               padding = 'post',\n","                               truncating = 'post',\n","                               maxlen = max_len)\n","\n","\n","sequence_test = tokenizer.texts_to_sequences(test_x)\n","seq_padd_test = pad_sequences(sequence_test, padding = 'post',\n","                              truncating = 'post',\n","                              maxlen = max_len)"]},{"cell_type":"markdown","metadata":{"id":"9GPBdovEzBmE"},"source":["### Q1 Calculating the Trainable Parameters of an LSTM\n","\n","Below is the summary of an LSTM neural network with embeddings and three layers. Explain in detail, after this cell, the \"why\" of the number of parameters of each of the layers displayed by `model1.summary()`. Cite any sources you used to answer this question."]},{"cell_type":"markdown","metadata":{"id":"_ch0XFkqgvgg"},"source":["`model1.summary()`\n","```\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, None)]            0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, None, 100)         2000100   \n","_________________________________________________________________\n","lstm (LSTM)                  (None, None, 128)         117248    \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, None, 96)          86400     \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 64)                41216     \n","_________________________________________________________________\n","predictions (Dense)          (None, 1)                 65        \n","=================================================================\n","Total params: 2,245,029\n","Trainable params: 2,245,029\n","Non-trainable params: 0\n","_________________________________________________________________\n","```"]},{"cell_type":"code","source":["# an integer input for vocab indices\n","inputs = tf.keras.Input(shape = (None,), dtype = 'int32')\n","\n","# define the layers below Embedding -> LSTM 1 -> LSTM 2\n","x = layers.Embedding(input_dim=20000+1, output_dim=100)(inputs)\n","\n","x = layers.LSTM(128, return_sequences=True)(x)\n","x = layers.LSTM(96, return_sequences=True)(x)\n","x = layers.LSTM(64)(x)\n","\n","# we project onto a single unit output layer, and squash it with a sigmoid\n","predictions = layers.Dense(1, activation = 'sigmoid', name = 'predictions')(x)\n","\n","model = tf.keras.Model(inputs, predictions, name = 'lstm_simple')\n","\n","# compile the model with binary crossentropy loss and an adam optimizer\n","model.compile(loss = 'binary_crossentropy',\n","               optimizer = 'adam',\n","               metrics = ['accuracy'])\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRWJoYM5dx_r","executionInfo":{"status":"ok","timestamp":1701737863592,"user_tz":360,"elapsed":1060,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"1a6398f3-a8f2-4715-87f7-2ac2c11daaa6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"lstm_simple\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_5 (Embedding)     (None, None, 100)         2000100   \n","                                                                 \n"," lstm_14 (LSTM)              (None, None, 128)         117248    \n","                                                                 \n"," lstm_15 (LSTM)              (None, None, 96)          86400     \n","                                                                 \n"," lstm_16 (LSTM)              (None, 64)                41216     \n","                                                                 \n"," predictions (Dense)         (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 2245029 (8.56 MB)\n","Trainable params: 2245029 (8.56 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"ejPWV0vj0J34"},"source":["**Why do we have the number of parameters after each of the layers?**\n","\n","* The embedding layer has 2,000,100 weights, which come from 20,000 tokens for in-vocab words, 1 token for out of vocab words, and then each multiplied by 100 for the embedding layer dimension.\n","\n","For each of the LSTM layers the number of parameters are calculated by taking the output from the previous layer, adding it to the memory size of the current layer, multiplying that amount by the current layer size, and then adding the current layer size again for the biases of each. That is then multiplied by 4 for the number of gates in the LSTM layer.\n","* The 1st LSTM layer has 117,248 parameters, which comes from 128 token memory size and 100 output from the embedding layers: ((128 + 100) * 128 + 128) * 4 = 117,248\n","* The 2nd LSTM layer has 86,400 parameters, which comes from 96 token memory size and 128 from the 1st LSTM later: ((96 + 128) * 96 + 96) * 4 = 86,400\n","* The 3rd LSTM layer has 41,216 parameters, which comes from 64 token memory size and 96 from the 2nd LSTM layer: ((64 + 96) * 64 + 64) * 4 = 41,216\n"]},{"cell_type":"markdown","metadata":{"id":"r3JcopEi-R6f"},"source":["### Q2: LSTM for Detecting Sarcasm\n","\n","Modify the code below to create an embedding layer of dimension 50. The vocabulary size is in variable `vocab_size`, and remember to add one in the embedding for the \"out of vocabulary\" input. Define an LSTM with two layers, one with 64 memory size and the second with 32 memory size. Remember to use the suffix `2` for each of the variables you define (e.g., `x2`)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJ72k-16EJA9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701737547143,"user_tz":360,"elapsed":7727,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"6c05af7b-03fc-47ff-f997-5de0e865587d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"lstm_simple\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, None, 50)          1294950   \n","                                                                 \n"," lstm (LSTM)                 (None, None, 64)          29440     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 32)                12416     \n","                                                                 \n"," predictions (Dense)         (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 1336839 (5.10 MB)\n","Trainable params: 1336839 (5.10 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# an integer input for vocab indices\n","inputs2 = tf.keras.Input(shape = (None,), dtype = 'int32')\n","\n","# define the layers below Embedding -> LSTM 1 -> LSTM 2\n","x2 = layers.Embedding(input_dim=vocab_size + 1, output_dim=50)(inputs2)\n","\n","x2 = layers.LSTM(64, return_sequences=True)(x2)\n","x2 = layers.LSTM(32)(x2)\n","\n","# we project onto a single unit output layer, and squash it with a sigmoid\n","predictions2 = layers.Dense(1, activation = 'sigmoid', name = 'predictions')(x2)\n","\n","model2 = tf.keras.Model(inputs2, predictions2, name = 'lstm_simple')\n","\n","# compile the model with binary crossentropy loss and an adam optimizer\n","model2.compile(loss = 'binary_crossentropy',\n","               optimizer = 'adam',\n","               metrics = ['accuracy'])\n","\n","model2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HtQCIAoOEREC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701738174714,"user_tz":360,"elapsed":53495,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"fa9d3869-e5d8-4d53-94b2-b16b8bb5f09d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","282/282 - 26s - loss: 0.4199 - accuracy: 0.7919 - val_loss: 0.3365 - val_accuracy: 0.8555 - 26s/epoch - 93ms/step\n","Epoch 2/10\n","282/282 - 5s - loss: 0.1815 - accuracy: 0.9314 - val_loss: 0.3476 - val_accuracy: 0.8510 - 5s/epoch - 17ms/step\n","Epoch 3/10\n","282/282 - 3s - loss: 0.0850 - accuracy: 0.9711 - val_loss: 0.4568 - val_accuracy: 0.8360 - 3s/epoch - 10ms/step\n","Epoch 4/10\n","282/282 - 3s - loss: 0.0479 - accuracy: 0.9842 - val_loss: 0.5865 - val_accuracy: 0.8285 - 3s/epoch - 10ms/step\n","Epoch 5/10\n","282/282 - 4s - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.7561 - val_accuracy: 0.8325 - 4s/epoch - 13ms/step\n","Epoch 6/10\n","282/282 - 2s - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.8686 - val_accuracy: 0.8240 - 2s/epoch - 8ms/step\n","Epoch 7/10\n","282/282 - 2s - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.8191 - val_accuracy: 0.8270 - 2s/epoch - 8ms/step\n","Epoch 8/10\n","282/282 - 2s - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.9685 - val_accuracy: 0.8325 - 2s/epoch - 8ms/step\n","Epoch 9/10\n","282/282 - 3s - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.8560 - val_accuracy: 0.8310 - 3s/epoch - 9ms/step\n","Epoch 10/10\n","282/282 - 4s - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.9479 - val_accuracy: 0.8355 - 4s/epoch - 13ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7cd51aaf9150>"]},"metadata":{},"execution_count":21}],"source":["epochs = 10\n","# fit the model using the train and test datasets\n","model2.fit(seq_padd_train, train_y,\n","           validation_split = 0.1,\n","           epochs = epochs,\n","           verbose = 2,\n","           batch_size = 64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSQR8VMIEYur","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701738175793,"user_tz":360,"elapsed":1097,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"8e71de78-8832-4ff1-ad95-606c6b5ba751"},"outputs":[{"output_type":"stream","name":"stdout","text":["270/270 [==============================] - 1s 4ms/step - loss: 0.9401 - accuracy: 0.8296\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.9400595426559448, 0.8295626044273376]"]},"metadata":{},"execution_count":22}],"source":["# estimate the test performance\n","model2.evaluate(seq_padd_test, test_y)"]},{"cell_type":"markdown","metadata":{"id":"lOvzWswaN3_g"},"source":["### Q3: GloVe Word Embeddings\n","\n","Use the code below to download the GloVe embeddings and create the matrix `embedding_matrix` corresponding to the vocabulary above. Define a layer `embedding_layer_glove` which will be use by the LSTM below. Evaluate the performance and compare to model above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNWYqooOL2Km","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701745998702,"user_tz":360,"elapsed":193584,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"7a5cb28b-8db7-44eb-945a-27b5ba6cdb16"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-05 03:10:00--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2023-12-05 03:10:00--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2023-12-05 03:10:01--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  1.85MB/s    in 3m 11s  \n","\n","2023-12-05 03:13:13 (4.30 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"]}],"source":["! wget http://nlp.stanford.edu/data/glove.6B.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzplxdY7Oi5I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701746024417,"user_tz":360,"elapsed":25722,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"0222b346-5912-4f38-a501-a2906c08181c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"]}],"source":["! unzip glove.6B.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EgIsgRm-Ok1h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701746034756,"user_tz":360,"elapsed":10357,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"104ba89f-876a-40b3-ac82-d628f71aed32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400000 word vectors.\n"]}],"source":["import os\n","embeddings_index = {}\n","f = open('glove.6B.100d.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype = 'float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print('Found %s word vectors.' % len(embeddings_index))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mkd0RxToOtcB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701746034756,"user_tz":360,"elapsed":21,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"f240e11b-7bdf-40f5-c9da-e68cac558c8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Converted 21242 words (4656 misses)\n"]}],"source":["num_tokens = vocab_size + 2\n","embedding_dim3 = 100\n","hits = 0\n","misses = 0\n","\n","# prepare embedding matrix\n","embedding_matrix = np.zeros((num_tokens, embedding_dim3))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        # this includes the representation for \"padding\" and \"OOV\"\n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","print(\"Converted %d words (%d misses)\" % (hits, misses))"]},{"cell_type":"markdown","metadata":{"id":"VGynV5Vla4s0"},"source":["Create the embedding layer below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEG5zcMhPatR"},"outputs":[],"source":["# create the embedding layer using the embedding_matrix from above\n","embedding_layer_glove = layers.Embedding(\n","    num_tokens,\n","    embedding_dim3,\n","    input_length = max_len,\n","    embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix),\n","    trainable = False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6UHnlij6Plr4"},"outputs":[],"source":["# an integer input for vocab indices\n","inputs3 = tf.keras.Input(shape = (None,), dtype = 'int32')\n","\n","# next, we add a layer to map those vocab indices into a space of dimensionality\n","x3 = embedding_layer_glove(inputs3)\n","\n","x3 = layers.LSTM(32)(x3)\n","\n","# we project onto a single unit output layer, and squash it with a sigmoid\n","predictions3 = layers.Dense(1, activation = 'sigmoid', name = 'predictions')(x3)\n","\n","model3 = tf.keras.Model(inputs3, predictions3)\n","\n","# compile the model with binary crossentropy loss and an adam optimizer.\n","model3.compile(loss = 'binary_crossentropy',\n","               optimizer = 'adam',\n","               metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izs4Y_kgPsPG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701743059922,"user_tz":360,"elapsed":22513,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"2d337f3b-8f61-41d2-f359-16c941555a8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","282/282 - 9s - loss: 0.5332 - accuracy: 0.7270 - val_loss: 0.4423 - val_accuracy: 0.8030 - 9s/epoch - 31ms/step\n","Epoch 2/10\n","282/282 - 1s - loss: 0.4036 - accuracy: 0.8201 - val_loss: 0.3932 - val_accuracy: 0.8270 - 1s/epoch - 4ms/step\n","Epoch 3/10\n","282/282 - 1s - loss: 0.3557 - accuracy: 0.8459 - val_loss: 0.3721 - val_accuracy: 0.8395 - 1s/epoch - 4ms/step\n","Epoch 4/10\n","282/282 - 1s - loss: 0.3218 - accuracy: 0.8627 - val_loss: 0.3627 - val_accuracy: 0.8455 - 1s/epoch - 4ms/step\n","Epoch 5/10\n","282/282 - 1s - loss: 0.3014 - accuracy: 0.8729 - val_loss: 0.3543 - val_accuracy: 0.8530 - 1s/epoch - 4ms/step\n","Epoch 6/10\n","282/282 - 1s - loss: 0.2791 - accuracy: 0.8838 - val_loss: 0.3737 - val_accuracy: 0.8310 - 1s/epoch - 4ms/step\n","Epoch 7/10\n","282/282 - 2s - loss: 0.2614 - accuracy: 0.8931 - val_loss: 0.3470 - val_accuracy: 0.8570 - 2s/epoch - 6ms/step\n","Epoch 8/10\n","282/282 - 2s - loss: 0.2435 - accuracy: 0.9012 - val_loss: 0.3462 - val_accuracy: 0.8650 - 2s/epoch - 6ms/step\n","Epoch 9/10\n","282/282 - 1s - loss: 0.2317 - accuracy: 0.9076 - val_loss: 0.3586 - val_accuracy: 0.8615 - 1s/epoch - 4ms/step\n","Epoch 10/10\n","282/282 - 1s - loss: 0.2099 - accuracy: 0.9179 - val_loss: 0.3445 - val_accuracy: 0.8555 - 1s/epoch - 4ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ab25497e170>"]},"metadata":{},"execution_count":16}],"source":["# fit the model using the train and test datasets\n","epochs = 10\n","model3.fit(seq_padd_train, train_y,\n","           validation_split = 0.1,\n","           epochs = epochs,\n","           verbose = 2,\n","           batch_size = 64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxwFJaqyPuxm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701743061241,"user_tz":360,"elapsed":1336,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"9f575d96-6f83-4b08-cb95-e97f68aefa03"},"outputs":[{"output_type":"stream","name":"stdout","text":["270/270 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8536\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.3347955048084259, 0.8535792827606201]"]},"metadata":{},"execution_count":17}],"source":["model3.evaluate(seq_padd_test, test_y)"]},{"cell_type":"markdown","metadata":{"id":"pj7HmAtdbbzh"},"source":["Is it better or worse performance compared to `model2`? Why?\n","\n","*With just the 10 epoches, Model3 performed slightly better than model2, with 85.36% test accuracy compared to 82.86% accuracy for model2. It also looks like model2 might have overfit the data since the training accuracy is much higher than the validation accuracy.*"]},{"cell_type":"markdown","metadata":{"id":"6y6P_ep9P5r3"},"source":["### Q4: Word Analogies\n","\n","Above, we created the matrix `embedding_matrix` for the vocabulary in the sarcasm dataset. Use the code below to find the word analogy to \"`germany` is to `berlin` as `uk` is to _blank_\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_u99fXdhPzRF"},"outputs":[],"source":["# we will first create the nearest neighbor model\n","nbrs_glove = NearestNeighbors(n_neighbors = 5, metric = 'cosine').fit(embedding_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0YSx1cpsQa2P"},"outputs":[],"source":["# let's check if it works\n","embedding_man = embedding_matrix[word_index['man']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vlamFoD3QThr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701743359332,"user_tz":360,"elapsed":122,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"5131690c-079e-4684-f89f-383687f58743"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['man', 'woman', 'boy', 'one', 'person']"]},"metadata":{},"execution_count":20}],"source":["# closest words to `man`\n","dist, idx = nbrs_glove.kneighbors([embedding_man])\n","[index_word[i] for i in idx[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWGeWlZjQpd9"},"outputs":[],"source":["# now define the proper embedding to solve the analogy\n","blank_embedding = embedding_matrix[word_index['germany']]\n","blank_embedding1 = embedding_matrix[word_index['berlin']]\n","blank_embedding2 = embedding_matrix[word_index['uk']]\n","blank_embedding3 = blank_embedding1 - blank_embedding + blank_embedding2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aCoYOiNPRif1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701744218068,"user_tz":360,"elapsed":135,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"4702da49-a69d-4a94-8fbf-41fbec53dcee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['uk', 'london', 'theatre', '2013', '2011']"]},"metadata":{},"execution_count":31}],"source":["# find the closest to blank_embedding\n","# closest words to `man`\n","dist, idx = nbrs_glove.kneighbors([blank_embedding3])\n","[index_word[i] for i in idx[0]]"]},{"cell_type":"markdown","source":["Answer: ***London***"],"metadata":{"id":"H17bZLO-3MeS"}},{"cell_type":"markdown","metadata":{"id":"s6Py0Xc3SFln"},"source":["### Q5: Biases\n","\n","As we discussed in class, there might be several biases in word embeddings. Use the list of occupations below and for each of them find whether `man` or `woman` is closest to it. In particular, first list all occupations that are closer to `man` than `woman`, and then all occupations that are closer to `woman` than `man`.\n","\n","_Hint_: Use the `cosine` distance between pairs of embeddings from the `SciPy` package. If the ocupation does not exist in the embedding matrix, skip it. Also, remember that the cosine distance is smaller when the embeddings are more similar.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gr4lsaweTPG1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701746034756,"user_tz":360,"elapsed":19,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"141384ec-7f42-42a5-9cff-f54570bd6254"},"outputs":[{"output_type":"stream","name":"stdout","text":["cosine([1,1], [1,1]):  0\n","cosine([1,1], [0,1]):  0.29289321881345254\n"]}],"source":["from scipy.spatial.distance import cosine\n","print('cosine([1,1], [1,1]): ', cosine([1,1], [1,1]))\n","print('cosine([1,1], [0,1]): ', cosine([1,1], [0,1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1wk0iujRmyd"},"outputs":[],"source":["occupation_list = \"\"\"technician, accountant, supervisor, engineer, worker, educator, clerk, counselor,\n","inspector, mechanic, manager, therapist, administrator, salesperson, receptionist, librarian,\n","advisor, pharmacist, janitor, psychologist, physician, carpenter, nurse, investigator,\n","bartender, specialist, electrician, officer, pathologist, teacher, lawyer, planner, practitioner,\n","plumber, instructor, surgeon, veterinarian, paramedic, examiner, chemist, machinist,\n","appraiser, nutritionist, architect, hairdresser, baker, programmer, paralegal, hygienist,\n","scientist\"\"\".replace('\\n', '').replace(' ', '').split(',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRIFdlWFSw_q"},"outputs":[],"source":["man_embedding = embedding_matrix[word_index['man']]\n","woman_embedding = embedding_matrix[word_index['woman']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEMLYEn4S_l3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701747184193,"user_tz":360,"elapsed":527,"user":{"displayName":"Bryan Crigger","userId":"02823606170186769987"}},"outputId":"43c0369a-e352-4399-8c97-bf9a09d4ed6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Male Occupations (according to Embedding Space):\n","engineer\n","inspector\n","mechanic\n","manager\n","advisor\n","carpenter\n","investigator\n","officer\n","lawyer\n","planner\n","plumber\n","instructor\n","architect\n","scientist\n","\n","Female Occupations (according to Embedding Space):\n","technician\n","supervisor\n","worker\n","educator\n","clerk\n","counselor\n","therapist\n","administrator\n","receptionist\n","librarian\n","pharmacist\n","janitor\n","psychologist\n","physician\n","nurse\n","bartender\n","teacher\n","practitioner\n","surgeon\n","veterinarian\n","paramedic\n","examiner\n","nutritionist\n","hairdresser\n","hygienist\n"]}],"source":["# first print the ocupations that are for a man, as perceived by GloVe\n","print(\"Male Occupations (according to Embedding Space):\")\n","for occupation in occupation_list:\n","  if occupation in word_index:\n","    ## If occupation closer to man_embedding than woman_embedding, print occupation\n","    if cosine(embedding_matrix[word_index[occupation]], man_embedding) < cosine(embedding_matrix[word_index[occupation]], woman_embedding):\n","      print(occupation)\n","# second print the ocupations that are for a woman, as perceived by GloVe\n","print(\"\\nFemale Occupations (according to Embedding Space):\")\n","for occupation in occupation_list:\n","  if occupation in word_index:\n","    if cosine(embedding_matrix[word_index[occupation]], man_embedding) > cosine(embedding_matrix[word_index[occupation]], woman_embedding):\n","      print(occupation)"]},{"cell_type":"markdown","metadata":{"id":"NK72utxcUnVd"},"source":["Do you see a pattern in the results? Do you think there are biases?\n","\n","**I think these results seem pretty fair and realistic, and therefore I suppose not that biased. I would say that if anything there may be more occupations that are categorized at \"female\" occupations that are probably more split between genders like \"bartender\" or \"paramedic\". There doesn't seem to be a pattern as far as jobs that require more schooling, or jobs that require more manual labor as being labeled as one gender's profession over another.**"]},{"cell_type":"markdown","metadata":{"id":"nr26TxJncSI8"},"source":["### Q6: Sequence to Sequence Embedding\n","\n","What is the problem with LSTM models, and why do we need **attention** to fix them? Give as an example of what happens with sequence to sequence models for translation."]},{"cell_type":"markdown","metadata":{"id":"T8VFfCmAcdmh"},"source":["**LSTM models start to become less efficient with large input sequences. Even though LSTM models were originally designed to capture context within long sequences of data, the longer you make the context window the larger the model gets, increases exponentially. Another problem with LSTM models is that they feed in data sequentially which cause longer processing times. Attention helps with this by focusing on one word/data point at a time and uses an embedding space for each word to predict each output value, which allows for parallel processing and faster processing times.**"]},{"cell_type":"code","source":[],"metadata":{"id":"j7XOnQDNyD8w"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}